{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#31394d'>Practical Exercise: k-Nearest Neighbours</font>\n",
    "\n",
    "In this notebook, we are going to train a k-nearest neighbours model using the [`scikit-learn`](https://scikit-learn.org) library. k-nearest neighbours is a *supervised learning* technique that is suitable for both *regression* (a continuous/numerical outcome) and *classification* (a categorical outcome). In this notebook, we will use it for regression.  \n",
    "\n",
    "We begin by importing modules for data wrangling:\n",
    "\n",
    "<!-- \n",
    "Even though its name is scikit-learn, it is imported as `sklearn`. It has many submodules.\n",
    "For example, the `datasets` submodule has a group of simple datasets that can be used to evaluate models without having to use external files.\n",
    "\n",
    "The Boston Housing dataset is available as a scikitlearn dataset.-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#31394d'> Get and Explore the Data </font>\n",
    "\n",
    "We'll be using is the [Boston Housing](https://www.kaggle.com/c/boston-housing) dataset from Kaggle. This dataset consists of information about houses in the Boston area. Our goal is to **predict the typical price of a house**.\n",
    "\n",
    "We import the data from the ``sklearn`` module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` datasets behave like a dictionary. Let's see what this dictionary contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DESCR` key includes a description of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `target` key holds the target/outcome variable; in this case, the median house value in thousands of dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the features/independent variables are stored under the `feature_names` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the values of the features are stored as a numpy array under the `data` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the Boston data into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "\n",
    "df[\"PRICE\"] = boston[\"target\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#31394d'> Training a KNN Model </font>\n",
    "\n",
    "The algorithms for fitting k-nearest neighbours models are in the `neighbors` submodule of `sklearn`. There are `KNeighborsRegressor` and `KNeighborsClassifier` classes for KNN regression and classification, respectively. Since we're dealing with a continuous outcome variable (`PRICE`), we'll import the `KNeighborsRegressor` class and create (instantiate) an *estimator* object. Note that this is the standard procedure for any machine learning algo available in `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object that we have called `knn` is our as yet untrained machine learning model. After training, it will be updated to contain all the information that is needed to make predictions on new data. Since we did not specify anything between the brackets in `KNeighborsRegressor()`, the object will be instantiated with the default parameters. It is usually a good idea to inspect these defaults (so that you understand the specifics of the model you are fitting) and to change them if needs be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        KNeighborsRegressor\n",
      "\u001b[1;31mString form:\u001b[0m KNeighborsRegressor()\n",
      "\u001b[1;31mFile:\u001b[0m        c:\\users\\ronle\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\n",
      "\u001b[1;31mDocstring:\u001b[0m  \n",
      "Regression based on k-nearest neighbors.\n",
      "\n",
      "The target is predicted by local interpolation of the targets\n",
      "associated of the nearest neighbors in the training set.\n",
      "\n",
      "Read more in the :ref:`User Guide <regression>`.\n",
      "\n",
      ".. versionadded:: 0.9\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_neighbors : int, default=5\n",
      "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      "\n",
      "weights : {'uniform', 'distance'} or callable, default='uniform'\n",
      "    weight function used in prediction.  Possible values:\n",
      "\n",
      "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
      "      are weighted equally.\n",
      "    - 'distance' : weight points by the inverse of their distance.\n",
      "      in this case, closer neighbors of a query point will have a\n",
      "      greater influence than neighbors which are further away.\n",
      "    - [callable] : a user-defined function which accepts an\n",
      "      array of distances, and returns an array of the same shape\n",
      "      containing the weights.\n",
      "\n",
      "    Uniform weights are used by default.\n",
      "\n",
      "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      "    Algorithm used to compute the nearest neighbors:\n",
      "\n",
      "    - 'ball_tree' will use :class:`BallTree`\n",
      "    - 'kd_tree' will use :class:`KDTree`\n",
      "    - 'brute' will use a brute-force search.\n",
      "    - 'auto' will attempt to decide the most appropriate algorithm\n",
      "      based on the values passed to :meth:`fit` method.\n",
      "\n",
      "    Note: fitting on sparse input will override the setting of\n",
      "    this parameter, using brute force.\n",
      "\n",
      "leaf_size : int, default=30\n",
      "    Leaf size passed to BallTree or KDTree.  This can affect the\n",
      "    speed of the construction and query, as well as the memory\n",
      "    required to store the tree.  The optimal value depends on the\n",
      "    nature of the problem.\n",
      "\n",
      "p : int, default=2\n",
      "    Power parameter for the Minkowski metric. When p = 1, this is\n",
      "    equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      "    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      "\n",
      "metric : str or callable, default='minkowski'\n",
      "    the distance metric to use for the tree.  The default metric is\n",
      "    minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      "    metric. See the documentation of :class:`DistanceMetric` for a\n",
      "    list of available metrics.\n",
      "    If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      "    must be square during fit. X may be a :term:`sparse graph`,\n",
      "    in which case only \"nonzero\" elements may be considered neighbors.\n",
      "\n",
      "metric_params : dict, default=None\n",
      "    Additional keyword arguments for the metric function.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of parallel jobs to run for neighbors search.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "    Doesn't affect :meth:`fit` method.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "effective_metric_ : str or callable\n",
      "    The distance metric to use. It will be same as the `metric` parameter\n",
      "    or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      "    'minkowski' and `p` parameter set to 2.\n",
      "\n",
      "effective_metric_params_ : dict\n",
      "    Additional keyword arguments for the metric function. For most metrics\n",
      "    will be same with `metric_params` parameter, but may also contain the\n",
      "    `p` parameter value if the `effective_metric_` attribute is set to\n",
      "    'minkowski'.\n",
      "\n",
      "n_samples_fit_ : int\n",
      "    Number of samples in the fitted data.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> X = [[0], [1], [2], [3]]\n",
      ">>> y = [0, 0, 1, 1]\n",
      ">>> from sklearn.neighbors import KNeighborsRegressor\n",
      ">>> neigh = KNeighborsRegressor(n_neighbors=2)\n",
      ">>> neigh.fit(X, y)\n",
      "KNeighborsRegressor(...)\n",
      ">>> print(neigh.predict([[1.5]]))\n",
      "[0.5]\n",
      "\n",
      "See Also\n",
      "--------\n",
      "NearestNeighbors\n",
      "RadiusNeighborsRegressor\n",
      "KNeighborsClassifier\n",
      "RadiusNeighborsClassifier\n",
      "\n",
      "Notes\n",
      "-----\n",
      "See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      "for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      "\n",
      ".. warning::\n",
      "\n",
      "   Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      "   neighbors, neighbor `k+1` and `k`, have identical distances but\n",
      "   different labels, the results will depend on the ordering of the\n",
      "   training data.\n",
      "\n",
      "https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n"
     ]
    }
   ],
   "source": [
    "?knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚀 <font color='#d9c4b1'> Exercise: </font> What is the default value of k?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value of k is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the model to our boston dataset using the `knn` object's `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X=df.iloc[:,:-1], y=df.PRICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `knn` object has now been updated so it is ready to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.78, 22.9 , 25.36, 26.06, 27.1 , 27.1 , 20.88, 19.1 , 18.4 ,\n",
       "       19.48, 19.28, 22.  , 24.34, 20.52, 24.66, 21.3 , 30.48, 20.4 ,\n",
       "       15.7 , 23.54, 16.82, 17.64, 18.3 , 17.08, 16.66, 15.1 , 16.78,\n",
       "       14.94, 19.94, 18.34, 14.1 , 16.82, 15.12, 14.1 , 15.12, 26.92,\n",
       "       22.14, 27.4 , 28.44, 31.88, 31.88, 25.36, 25.36, 24.22, 20.68,\n",
       "       20.44, 20.44, 18.1 , 18.1 , 24.  , 21.54, 24.  , 27.16, 27.16,\n",
       "       25.7 , 39.82, 27.08, 38.28, 24.8 , 25.64, 21.78, 33.6 , 21.78,\n",
       "       24.06, 31.74, 25.3 , 26.98, 22.18, 20.42, 20.42, 27.76, 29.5 ,\n",
       "       27.76, 27.76, 22.92, 21.64, 25.82, 21.64, 21.38, 22.02, 24.8 ,\n",
       "       21.88, 25.22, 25.64, 25.98, 25.98, 23.28, 25.98, 24.02, 25.58,\n",
       "       25.58, 25.06, 26.34, 26.04, 30.1 , 24.84, 23.62, 24.32, 28.52,\n",
       "       24.96, 22.1 , 22.2 , 15.34, 19.74, 19.74, 19.66, 19.56, 21.34,\n",
       "       19.66, 19.56, 22.08, 20.1 , 19.6 , 17.54, 20.1 , 17.7 , 20.2 ,\n",
       "       20.1 , 20.66, 19.8 , 22.76, 20.6 , 19.66, 18.52, 19.66, 20.6 ,\n",
       "       18.52, 16.62, 18.04, 16.88, 18.4 , 18.4 , 18.78, 18.56, 20.24,\n",
       "       17.44, 17.8 , 18.4 , 15.88, 17.06, 15.24, 14.76, 15.62, 15.62,\n",
       "       15.62, 18.26, 18.26, 15.62, 17.82, 17.44, 37.22, 20.66, 19.28,\n",
       "       20.24, 20.24, 15.34, 15.34, 37.78, 25.52, 32.08, 20.66, 42.56,\n",
       "       44.54, 44.54, 30.34, 20.24, 37.22, 19.52, 19.98, 20.24, 19.98,\n",
       "       18.74, 21.9 , 24.4 , 23.74, 25.82, 22.34, 24.2 , 23.84, 38.56,\n",
       "       33.24, 38.56, 33.24, 31.6 , 33.24, 38.56, 37.84, 32.72, 33.14,\n",
       "       32.72, 33.14, 32.72, 33.72, 31.8 , 31.8 , 34.9 , 26.78, 25.24,\n",
       "       26.78, 29.38, 29.5 , 25.2 , 25.3 , 41.28, 41.28, 23.76, 23.78,\n",
       "       20.74, 22.9 , 21.1 , 21.1 , 21.1 , 23.9 , 28.84, 22.6 , 27.28,\n",
       "       22.96, 21.9 , 21.1 , 23.38, 25.42, 17.32, 31.8 , 24.46, 37.82,\n",
       "       36.46, 36.14, 35.96, 29.5 , 29.44, 34.  , 41.28, 38.28, 38.16,\n",
       "       28.12, 29.3 , 34.12, 34.12, 21.44, 21.92, 21.44, 21.4 , 22.1 ,\n",
       "       21.74, 20.  , 19.68, 22.16, 20.  , 21.38, 31.22, 31.22, 26.28,\n",
       "       29.56, 31.22, 27.08, 24.86, 38.28, 42.44, 38.9 , 36.48, 38.82,\n",
       "       41.88, 41.88, 37.9 , 41.88, 34.6 , 38.82, 36.16, 32.42, 31.74,\n",
       "       32.58, 28.82, 31.74, 26.88, 31.96, 31.96, 31.96, 31.96, 31.96,\n",
       "       30.58, 31.74, 32.58, 36.62, 42.8 , 24.84, 21.88, 38.64, 21.88,\n",
       "       24.44, 22.62, 34.9 , 34.9 , 31.88, 24.54, 23.28, 24.44, 23.22,\n",
       "       22.94, 25.28, 29.12, 25.42, 25.78, 28.02, 30.58, 31.22, 27.02,\n",
       "       31.96, 27.02, 23.72, 21.6 , 29.  , 21.32, 21.02, 20.94, 21.44,\n",
       "       21.6 , 18.54, 19.52, 20.5 , 21.3 , 23.32, 23.76, 23.32, 22.9 ,\n",
       "       22.06, 23.76, 26.14, 22.06, 19.7 , 21.22, 19.92, 21.86, 22.98,\n",
       "       23.6 , 21.16, 20.78, 25.74, 24.3 , 20.72, 22.64, 24.32, 24.44,\n",
       "       19.8 , 29.36, 26.58, 19.  , 18.84, 26.48, 33.32, 25.78, 25.78,\n",
       "       28.  , 30.46, 42.8 , 20.96, 24.8 , 15.88, 19.06, 20.94, 21.42,\n",
       "       33.8 , 25.6 , 30.94, 25.6 , 27.22, 27.22, 16.98, 14.58, 39.16,\n",
       "       39.16, 26.46, 36.6 , 27.22, 11.36, 10.54, 10.82, 12.36, 12.5 ,\n",
       "        9.6 , 10.22,  6.86, 10.26, 11.62, 11.62, 14.16, 11.  ,  8.94,\n",
       "        9.74, 13.18, 12.5 , 13.52, 21.66, 11.88, 15.58, 11.74, 13.54,\n",
       "       13.98, 12.46,  8.5 , 14.82,  9.54, 11.14, 15.88, 10.5 , 14.28,\n",
       "        6.86, 13.18, 18.56, 14.52, 17.62, 10.34, 12.74, 11.88, 17.18,\n",
       "       10.92, 11.88, 11.2 , 14.58, 11.96, 10.44, 16.98, 16.98, 14.16,\n",
       "       13.58, 12.94, 11.74, 12.56, 10.26, 13.52, 11.58, 14.  , 12.6 ,\n",
       "       13.52, 13.3 , 12.9 , 12.16, 12.1 , 10.56, 12.12, 11.96, 10.6 ,\n",
       "       14.56, 13.84, 13.34, 13.44, 12.44, 16.98, 13.34, 14.48, 16.06,\n",
       "       13.58, 15.54, 17.04, 16.62, 12.54, 12.2 , 13.58, 12.94, 14.84,\n",
       "       20.24, 14.34, 19.82, 20.24, 20.38, 22.28, 17.56, 12.74, 18.56,\n",
       "       23.7 , 21.26, 20.24, 18.6 , 22.72, 23.28, 15.54, 16.06, 14.18,\n",
       "       14.96, 15.88, 16.36, 22.28, 22.72, 23.44, 20.86, 22.8 , 21.34,\n",
       "       21.42, 21.34, 17.04, 11.54, 12.28, 14.86, 18.3 , 22.08, 21.82,\n",
       "       22.02, 18.7 , 18.7 , 20.64, 18.7 , 19.96, 21.18, 23.12, 20.88,\n",
       "       21.9 , 21.42])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = knn.predict(X=df.iloc[:,:-1])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our predicted prices look relative to the true prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='PRICE'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df.PRICE, y=y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#31394d'> Model Evaluation </font>\n",
    "\n",
    "We should never be used to evaulate a model's performance. Instead, we should evaluate our model on new, unseen data. We can do this in one of two ways: (1) split the data into training and test sets or (2) use cross-validation. Let's see how we would implement these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#31394d'> 1. Train/Test Split </font>\n",
    "\n",
    "Before we train our KNN model (i.e. call the `fit` method), we can split the data into training and test sets. We then call the `fit` method on the training set and the `predict` method on the test set. Usually, the training set is larger than the test set (75%/25% and 80%/20% splits are common).\n",
    "\n",
    "We can use the `train_test_split` function from the `sklearn` module to easily split the dataset into training and test subsets. We use the argument `test_size` to define the % size of the test dataset.\n",
    "\n",
    "The full dataset is divided row-wise into training and test sets *at random*. This means that each time we run `train_test_split`, we will get different datasets. In order to make sure that we get the same splits again and again, we can fix the *random seed*; that is, the number that numpy uses to start its random number generation (used to calculate the splits). We can use the argument `random_state` to set the random seed for `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 404 rows\n",
      "Test set has 102 rows\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=12345)\n",
    "\n",
    "print('Training set has', train.shape[0], 'rows')\n",
    "print('Test set has', test.shape[0], 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we <font color='#d9c4b1'>**FIT**</font> the model on the <font color='#d9c4b1'>**TRAINING DATA**</font>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsRegressor()\n",
    "model.fit(X=train.iloc[:,:-1], y=train.PRICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And <font color='#d9c4b1'>**PREDICT**</font> on the <font color='#d9c4b1'>**TEST DATA**</font>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X=test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate our evaluation metrics using scikit-learn's `metrics` submodule. These functions take the actual values and predicted values of the outcome variable as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.42091372549021"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true=test['PRICE'], y_pred=y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.732352941176471"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_true=test['PRICE'], y_pred=y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magnitudes of the MSE and MAE are dependent on how the outcome variable is measured. They are therefore not comparable across datasets, but are useful for model and feature selection on a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='#d9c4b1'> Choosing k </font>\n",
    "\n",
    "We can use the train/test split to find the optimal value for k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsRegressor(n_neighbors = 1) # K = 1\n",
    "knn1.fit(X=train.iloc[:,:-1], y=train.PRICE)\n",
    "y_hat1 = knn1.predict(X=test.iloc[:,:-1])\n",
    "\n",
    "knn3 = KNeighborsRegressor(n_neighbors = 3) # K = 3\n",
    "knn3.fit(X=train.iloc[:,:-1], y=train.PRICE)\n",
    "y_hat3 = knn3.predict(X=test.iloc[:,:-1])\n",
    "\n",
    "knn5 = KNeighborsRegressor(n_neighbors = 5) # K = 5\n",
    "knn5.fit(X=train.iloc[:,:-1], y=train.PRICE)\n",
    "y_hat5 = knn5.predict(X=test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "K = 1\t 5.447058823529412\n",
      "K = 3\t 4.669607843137255\n",
      "K = 5\t 4.732352941176471\n"
     ]
    }
   ],
   "source": [
    "print('MSE')\n",
    "print('K = 1\\t', mean_absolute_error(y_true=test['PRICE'], y_pred=y_hat1))\n",
    "print('K = 3\\t', mean_absolute_error(y_true=test['PRICE'], y_pred=y_hat3))\n",
    "print('K = 5\\t', mean_absolute_error(y_true=test['PRICE'], y_pred=y_hat5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN model with k=3 has the lowest MAE on new data and is therefore the best. \n",
    "\n",
    "🚀 <font color='#d9c4b1'> Exercise: </font> Try the MSE metric and see if you reach the same conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "K = 1\t 58.586078431372556\n",
      "K = 3\t 45.35454248366013\n",
      "K = 5\t 41.42091372549021\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print('MAE')\n",
    "print('K = 1\\t', mean_squared_error(y_true=test['PRICE'], y_pred=y_hat1))\n",
    "print('K = 3\\t', mean_squared_error(y_true=test['PRICE'], y_pred=y_hat3))\n",
    "print('K = 5\\t', mean_squared_error(y_true=test['PRICE'], y_pred=y_hat5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN model with k=5 has the lowest MSE on new data and is therefore the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#31394d'> 2. Cross Validation </font>\n",
    "\n",
    "Cross validation is an alternative approach to evaluate out-of-sample model performance. To do cross validation, we simply split the data into *K* folds, and for each fold, we train the model on the data from the *K*-1 remaining folds and evaluate on the one that was not included in the training set. That way, we get out-of-sample predictions and errors for every data point, so we don't rely on a single test set. \n",
    "\n",
    "For example, a 5 fold cross validation would look like this:\n",
    "\n",
    "![title](media/cross_validation.png)\n",
    "\n",
    "The `cross_val_score` function in `scikit-learn` computes your choice of evaluation metric for each fold. To use this function, we first need to see what \"scoring methods\" are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it defines the evaluation metrics such that \"bigger is better\". So, if we want to use MSE, for example, we need to choose \"neg_mean_squared_error\" (the negative MSE).\n",
    "\n",
    "Note that we do **NOT** do a train/test split. We use the full dataset in the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -72.84204314,  -77.44044752, -114.19790495,  -89.00506931,\n",
       "        -31.22948515])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_mod_5 = KNeighborsRegressor(n_neighbors = 5)\n",
    "\n",
    "cv_scores = cross_val_score(estimator=knn_mod_5, X=df.iloc[:,:-1], y=df.PRICE, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validated MSE for KNN model with $K=5$ is therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.9429900135896"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚀 <font color='#d9c4b1'> Exercise: </font> Repeat the above for $K=1$ and $K=3$, and determine which value is best using 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-125.2904902 , -112.53950495, -128.14732673,  -94.3809901 ,\n",
       "        -69.01316832])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_mod_1 = KNeighborsRegressor(n_neighbors = 1)\n",
    "\n",
    "cv_scores = cross_val_score(estimator=knn_mod_1, X=df.iloc[:,:-1], y=df.PRICE, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.87429605901768"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -79.7796841 ,  -71.24662266, -117.46986799,  -89.99253025,\n",
       "        -35.02322332])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_mod_3 = KNeighborsRegressor(n_neighbors = 3)\n",
    "\n",
    "cv_scores = cross_val_score(estimator=knn_mod_3, X=df.iloc[:,:-1], y=df.PRICE, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.7023856640566"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get more information about each split, we can use the `cross_validate` function instead. It also accepts multiple scoring functions/evaluation metrics. Think of `cross_val_score` as the simplified version of `cross_validate`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_negMSE</th>\n",
       "      <th>test_negMAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>-72.842043</td>\n",
       "      <td>-6.519804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>-77.440448</td>\n",
       "      <td>-5.703960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>-114.197905</td>\n",
       "      <td>-7.652871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>-89.005069</td>\n",
       "      <td>-6.091881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007197</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>-31.229485</td>\n",
       "      <td>-4.113465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_negMSE  test_negMAE\n",
       "0  0.007996    0.009001   -72.842043    -6.519804\n",
       "1  0.006998    0.009002   -77.440448    -5.703960\n",
       "2  0.010013    0.007986  -114.197905    -7.652871\n",
       "3  0.009004    0.010004   -89.005069    -6.091881\n",
       "4  0.007197    0.008799   -31.229485    -4.113465"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring_functions = {\"negMSE\": \"neg_mean_squared_error\", \"negMAE\": \"neg_mean_absolute_error\"}\n",
    "cv_info = cross_validate(estimator=model, X=df.iloc[:,:-1], y=df.PRICE, scoring=scoring_functions, cv=5, return_train_score=False)\n",
    "cv_df = pd.DataFrame(cv_info)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get results for each one of the folds:\n",
    "- fit time = how long it took to train the model\n",
    "- score time = how long it took to make predictions and compute the score\n",
    "- test and train scores are given for each one of the scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_negMSE   -76.942990\n",
       "test_negMAE    -6.016396\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.loc[:,cv_df.columns.str.startswith('test')].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8479e3e531610f749506ed574c777af35093ce5912ea72dea5ed5fb1a626144b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
